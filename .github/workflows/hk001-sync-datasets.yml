name: HK001 Sync Datasets
on:
  schedule:
    - cron: '0 */6 * * *' # every 6 hours
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - ".github/workflows/config/hk001-datasets.json"
      - ".github/workflows/hk001-sync-datasets.yml"

concurrency:
  group: hk001-sync-datasets-${{ github.ref }}
  cancel-in-progress: false

jobs:
  sync_datasets:
    runs-on: linux-aarch64-sync-hk001
    container:
      image: python:3.11-slim
    steps:
      - uses: actions/checkout@v4

      - name: Install system dependencies
        run: |
          apt-get update
          apt-get install -y jq

      - name: Set up Python environment
        run: |
          pip config set global.index-url https://mirrors.huaweicloud.com/repository/pypi/simple
          pip install --upgrade pip
          pip install filelock modelscope datasets huggingface_hub[cli]

      - name: Download datasets
        run: |
          echo "Reading dataset configurations from .github/workflows/config/hk001-datasets.json"
          
          # Read and process each dataset configuration
          jq -c '.[]' .github/workflows/config/hk001-datasets.json | while IFS= read -r dataset_config; do
            platform=$(echo "$dataset_config" | jq -r '.platform')
            organization=$(echo "$dataset_config" | jq -r '.organization')
            dataset_name=$(echo "$dataset_config" | jq -r '.dataset_name')
            
            echo "Processing dataset: $organization/$dataset_name from $platform"
            
            if [ "$platform" = "modelscope" ]; then
              echo "Downloading from ModelScope to default path..."
              modelscope download --dataset "$organization/$dataset_name" || echo "Failed to download $organization/$dataset_name from ModelScope"
              
            elif [ "$platform" = "huggingface" ]; then
              echo "Downloading from HuggingFace to /root/.cache/datasets/$organization/$dataset_name..."
              download_path="/root/.cache/datasets/$organization/$dataset_name"
              mkdir -p "$download_path" || { echo "Failed to create directory $download_path"; exit 1; }
              
              # Download using huggingface-cli
              huggingface-cli download "$organization/$dataset_name" --local-dir "$download_path" --local-dir-use-symlinks False || echo "Failed to download $organization/$dataset_name from HuggingFace"
              
            else
              echo "Unknown platform: $platform. Skipping $organization/$dataset_name"
            fi
            
            echo "Completed processing $organization/$dataset_name"
            echo "---"
          done